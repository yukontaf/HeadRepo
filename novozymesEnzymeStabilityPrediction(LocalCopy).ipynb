{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "DqvAfHXqxUYC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd, numpy as np, matplotlib.pyplot as plt, matplotlib\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '1'\n",
        "from tensorflow import keras\n",
        "tf.config.run_functions_eagerly(True)\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.losses import MeanAbsoluteError, MeanSquaredError\n",
        "from tensorflow.keras.optimizers import Adagrad, Adadelta, Adam, Adamax, Ftrl, Nadam, SGD, RMSprop \n",
        "from tensorflow.keras.layers import Bidirectional, Dense, LSTM, GRU, Conv1D, GlobalAveragePooling1D, Lambda, Flatten, Dropout, Embedding, Input\n",
        "from tqdm import tqdm\n",
        "matplotlib.style.use(\"seaborn-whitegrid\")\n",
        "pd.set_option(\"display.width\", 5000)\n",
        "pd.set_option(\"display.max_columns\", 60)\n",
        "plt.rcParams[\"figure.figsize\"] = (15, 10)\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
        "# AUTO = tf.data.experimental.AUTOTUNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xu6m1iQkcdRa"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# !pip install optuna\n",
        "# !pip install ipdb\n",
        "# !apt install --allow-change-held-packages libcudnn8=8.4.1.50-1+cuda11.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LCwoZ9JT4sk8"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "import ipdb\n",
        "from optuna.trial import TrialState"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OdJ_ise1qMPY"
      },
      "outputs": [],
      "source": [
        "df = pd.read_feather('train.feather')\n",
        "df = df.drop('data_source', axis=1)\n",
        "df = df.fillna(0)\n",
        "train = df.sample(frac = 0.8)\n",
        "val = df.drop(train.index, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VjpEHcvlxUYI"
      },
      "outputs": [],
      "source": [
        "def split_seq(df):\n",
        "    sentences = np.array([\n",
        "    df[['protein_sequence']].to_numpy()[:, 0],\n",
        "])\n",
        "    splitted= []\n",
        "    for i in sentences[0, :]:\n",
        "        splitted.append(list(i))\n",
        "\n",
        "    return np.array(splitted)\n",
        "\n",
        "train_seq, test_seq = split_seq(train), split_seq(val)\n",
        "\n",
        "train_ph, val_ph = train['pH'].to_numpy().reshape((len(train), 1)), val['pH'].to_numpy().reshape((len(val), 1))\n",
        "train_tm, val_tm = train['tm'].to_numpy().reshape((len(train), 1)), val['tm'].to_numpy().reshape((len(val), 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ro80MZB2ZMm",
        "outputId": "4ccad646-bfa9-4364-f7c5-466086e7c6d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2242.0"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['protein_sequence'].apply(lambda x: len(x)).quantile(0.99)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Q4Bd-xxfxUYJ"
      },
      "outputs": [],
      "source": [
        "max_length = 2250\n",
        "trunc_type='post'\n",
        "embedding_dim = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tdNq9IJfxUYJ"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_seq)\n",
        "sequences = tokenizer.texts_to_sequences(train_seq)\n",
        "padded = pad_sequences(sequences, maxlen=max_length, truncating=trunc_type)\n",
        "vocab_size = len(tokenizer.word_index)\n",
        "train = tf.data.Dataset.from_tensor_slices(np.append(np.append(padded, train_ph, 1), train_tm, 1))\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(test_seq)\n",
        "testing_padded = pad_sequences(testing_sequences,maxlen=max_length)\n",
        "val = tf.data.Dataset.from_tensor_slices(np.append(np.append(testing_padded, val_ph, 1), val_tm, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lo0y5tvepgqc"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "def preprocess(data):\n",
        "    sequence = data[:-1]\n",
        "    ph = tf.reshape(data[-2], (-1, ))\n",
        "    tm =  data[-1]\n",
        "    return sequence, ph, tm\n",
        "def get_training_dataset(dataset):\n",
        "    dataset = dataset.map(preprocess).shuffle(len(sequences)).batch(BATCH_SIZE)\n",
        "    return dataset\n",
        "def get_validation_dataset(valid):\n",
        "  valid = valid.map(preprocess).shuffle(len(sequences)).batch(BATCH_SIZE)\n",
        "  return valid\n",
        "def concat(input):\n",
        "  # if len(input[0].shape) >=2:\n",
        "  #   input[1] = tf.tile(tf.reshape(input[1], (-1, 1, 1)), (1, 1, input[0].shape[-1]))\n",
        "  #   return tf.keras.layers.concatenate([input[0], input[1]], axis=1)\n",
        "  # else:\n",
        "    return tf.keras.layers.concatenate([input[0], input[1]], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "w3JlzGcFePL-"
      },
      "outputs": [],
      "source": [
        "# %pdb\n",
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, lstm_layers, emb_dim, lstm_units, dropout_rate):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.lstm_layers, self.emb_dim, self.lstm_units, self.dropout_rate = lstm_layers, emb_dim, lstm_units, dropout_rate\n",
        "    self.input_ph = tf.keras.layers.Input((1,))\n",
        "    self.input_seq = tf.keras.layers.Input((500, ))\n",
        "    self.seq_layers =  [] \n",
        "    self.seq_layers.extend([tf.keras.layers.Embedding(21, emb_dim, name='embedding'),\n",
        "                        tf.keras.layers.Conv1D(filters=128, kernel_size=5, activation='relu'),\n",
        "                        tf.keras.layers.Dropout(dropout_rate),  \n",
        "                        tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
        "                        tf.keras.layers.Dropout(dropout_rate),\n",
        "                        *[tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(i, return_sequences=True, name=f'LSTM_{i}')) for j in range(lstm_layers-1) for i in lstm_units],\n",
        "                        ])\n",
        "    for i in range(len(self.seq_layers)):\n",
        "      vars(self)[f'SEQ_LAYER_{i}'] = self.seq_layers[i]\n",
        "\n",
        "    self.ph_layers = [\n",
        "                      tf.keras.layers.Dense(512, name='dense1_ph', activation='relu'),\n",
        "                      tf.keras.layers.Dropout(dropout_rate), \n",
        "                      tf.keras.layers.Dense(256, name='dense2_ph', activation='relu'),\n",
        "                      tf.keras.layers.Dropout(dropout_rate), \n",
        "                      tf.keras.layers.Dense(128, name='dense3_ph', activation='relu'),\n",
        "                      # tf.keras.layers.Dropout(dropout_rate),  \n",
        "                      # tf.keras.layers.Dense(1, name='output_ph')\n",
        "                      ]\n",
        "\n",
        "    self.lambda_layer = tf.keras.layers.Lambda(function=concat, name='lambda_layer')\n",
        "    self.flatten = tf.keras.layers.Flatten(name='flatten')\n",
        "    self.dense_combined = tf.keras.layers.Dense(64, activation='relu', name='dense_combined')\n",
        "    self.lambda_helper = tf.keras.layers.Lambda(lambda x: tf.reshape(x, (-1, 64, 1)))\n",
        "    self.lstm_dense = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(512))\n",
        "    self.last_dense = tf.keras.layers.Dense(1, name='output')\n",
        "\n",
        "  def call(self, inputs):\n",
        "    seq, ph = inputs\n",
        "    SEQ_LAYER_0 = vars(self)['SEQ_LAYER_0']\n",
        "    x = SEQ_LAYER_0(seq)\n",
        "    for i in range(1, self.lstm_layers):\n",
        "        SEQ_LAYER_i = vars(self)[f'SEQ_LAYER_{i}']\n",
        "        x = SEQ_LAYER_i(x)\n",
        "\n",
        "    # for layer in self.seq_layers:\n",
        "    #   seq = layer(seq)\n",
        "\n",
        "    for layer in self.ph_layers:\n",
        "      ph = layer(ph)\n",
        "\n",
        "    x = self.lambda_layer([x, tf.tile(tf.reshape(ph, (-1, 128, 1)), (1, 1, x.shape[-1]))])\n",
        "    x = self.flatten(x)\n",
        "    x = self.dense_combined(x)\n",
        "    x = self.lambda_helper(x)\n",
        "    x = self.lstm_dense(x)\n",
        "    x = self.last_dense(x)\n",
        "    return x\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CM324baOeGHf"
      },
      "outputs": [],
      "source": [
        "TRAIN_STEPS = 15\n",
        "PRUNING_INTERVAL_STEPS = 50\n",
        "def objective(trial):    \n",
        "  lstm_layers = trial.suggest_int('lstm_layers', 1, 7)\n",
        "  emb_dim = trial.suggest_int('emb_dim', 256, 1024)\n",
        "  lstm_units = []\n",
        "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-7, 1)\n",
        "  for i in range(lstm_layers):\n",
        "    lstm_units.append(trial.suggest_int(f'lstm_units_l{i}', 16, 512))\n",
        "  dropout_rate = trial.suggest_uniform('dropout_rate', 0, 1)\n",
        "  optimizer = trial.suggest_categorical('optimizer', [Adagrad, Adadelta, Adam, Adamax, Ftrl, Nadam, SGD, RMSprop])\n",
        "  regressor = MyModel(lstm_layers, emb_dim, lstm_units, dropout_rate)\n",
        "  loss_obj = tf.keras.metrics.MeanAbsoluteError(name='loss_obj')\n",
        "  regressor.compile(loss=loss_obj, optimizer=optimizer(learning_rate=learning_rate))\n",
        "  losses, n_train_iter, step = [], len(get_training_dataset(train)), 0\n",
        "  for epoch in range(1):\n",
        "    print(f'Epoch # {epoch} started')\n",
        "    for batch in tqdm(get_training_dataset(train)):\n",
        "      predictions = regressor([batch[0], batch[1]], training=True)\n",
        "      loss = loss_obj(batch[2], predictions)\n",
        "      losses.append(loss)\n",
        "      if step > n_train_iter//2:\n",
        "        intermediate_value = loss\n",
        "        if intermediate_value < best_loss:\n",
        "            raise optuna.TrialPruned()\n",
        "      step += 1\n",
        "      best_loss = min(losses)\n",
        "    print(f'Training Loss {loss:.2f}, Best Loss: {best_loss:.2f}')\n",
        "    for val_batch in tqdm(get_validation_dataset(val)):\n",
        "      predictions = regressor([val_batch[0], val_batch[1]], training=False)\n",
        "      val_loss = loss_obj(val_batch[2], predictions)\n",
        "    print(f'Validation Loss {val_loss:.2f}')\n",
        "  return val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELrn1aBzLs2P",
        "outputId": "ae19525a-2897-47ce-bcac-e41c9ec7a1b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-02 08:33:55,859]\u001b[0m A new study created in memory with name: no-name-6a75b006-2327-4191-9123-4ccff5d2dcfe\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch # 0 started\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▉         | 9/99 [01:00<10:02,  6.70s/it]\n",
            "\u001b[33m[W 2022-10-02 08:34:56,762]\u001b[0m Trial 0 failed because of the following error: InvalidArgumentError()\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/Volumes/Environment/conda/miniconda3/envs/defaultenv/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"/var/folders/t0/fw3jvl196_v78v94hzhxhpgw0000gn/T/ipykernel_85779/1214606070.py\", line 19, in objective\n",
            "    predictions = regressor([batch[0], batch[1]], training=True)\n",
            "  File \"/Volumes/Environment/conda/miniconda3/envs/defaultenv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/var/folders/t0/fw3jvl196_v78v94hzhxhpgw0000gn/T/ipykernel_85779/4287616964.py\", line 39, in call\n",
            "    x = SEQ_LAYER_0(seq)\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling layer \"embedding\" \"                 f\"(type Embedding).\n",
            "\n",
            "{{function_node __wrapped__ResourceGather_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[199,2250] = 49 is not in [0, 21) [Op:ResourceGather]\n",
            "\n",
            "Call arguments received by layer \"embedding\" \"                 f\"(type Embedding):\n",
            "  • inputs=tf.Tensor(shape=(256, 2251), dtype=float32)\n"
          ]
        },
        {
          "ename": "InvalidArgumentError",
          "evalue": "Exception encountered when calling layer \"embedding\" \"                 f\"(type Embedding).\n\n{{function_node __wrapped__ResourceGather_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[199,2250] = 49 is not in [0, 21) [Op:ResourceGather]\n\nCall arguments received by layer \"embedding\" \"                 f\"(type Embedding):\n  • inputs=tf.Tensor(shape=(256, 2251), dtype=float32)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[1;32m/Users/glebsokolov/Library/CloudStorage/GoogleDrive-yukontaf@gmail.com/My Drive/!HeadRepo/novozymesEnzymeStabilityPrediction(LocalCopy).ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/glebsokolov/Library/CloudStorage/GoogleDrive-yukontaf%40gmail.com/My%20Drive/%21HeadRepo/novozymesEnzymeStabilityPrediction%28LocalCopy%29.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/glebsokolov/Library/CloudStorage/GoogleDrive-yukontaf%40gmail.com/My%20Drive/%21HeadRepo/novozymesEnzymeStabilityPrediction%28LocalCopy%29.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/glebsokolov/Library/CloudStorage/GoogleDrive-yukontaf%40gmail.com/My%20Drive/%21HeadRepo/novozymesEnzymeStabilityPrediction%28LocalCopy%29.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m pruned_trials \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mget_trials(deepcopy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, states\u001b[39m=\u001b[39m[TrialState\u001b[39m.\u001b[39mPRUNED])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/glebsokolov/Library/CloudStorage/GoogleDrive-yukontaf%40gmail.com/My%20Drive/%21HeadRepo/novozymesEnzymeStabilityPrediction%28LocalCopy%29.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m complete_trials \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mget_trials(deepcopy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, states\u001b[39m=\u001b[39m[TrialState\u001b[39m.\u001b[39mCOMPLETE])\n",
            "File \u001b[0;32m/Volumes/Environment/conda/miniconda3/envs/defaultenv/lib/python3.8/site-packages/optuna/study/study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    316\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    325\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \n\u001b[1;32m    328\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m     _optimize(\n\u001b[1;32m    420\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    421\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    422\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    423\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    424\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    425\u001b[0m         catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[1;32m    426\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    427\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    428\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    429\u001b[0m     )\n",
            "File \u001b[0;32m/Volumes/Environment/conda/miniconda3/envs/defaultenv/lib/python3.8/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
            "File \u001b[0;32m/Volumes/Environment/conda/miniconda3/envs/defaultenv/lib/python3.8/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    161\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as CircleCI).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
            "File \u001b[0;32m/Volumes/Environment/conda/miniconda3/envs/defaultenv/lib/python3.8/site-packages/optuna/study/_optimize.py:234\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    230\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    231\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    233\u001b[0m ):\n\u001b[0;32m--> 234\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    235\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
            "File \u001b[0;32m/Volumes/Environment/conda/miniconda3/envs/defaultenv/lib/python3.8/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    197\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
            "\u001b[1;32m/Users/glebsokolov/Library/CloudStorage/GoogleDrive-yukontaf@gmail.com/My Drive/!HeadRepo/novozymesEnzymeStabilityPrediction(LocalCopy).ipynb Cell 13\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/glebsokolov/Library/CloudStorage/GoogleDrive-yukontaf%40gmail.com/My%20Drive/%21HeadRepo/novozymesEnzymeStabilityPrediction%28LocalCopy%29.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch # \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m started\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/glebsokolov/Library/CloudStorage/GoogleDrive-yukontaf%40gmail.com/My%20Drive/%21HeadRepo/novozymesEnzymeStabilityPrediction%28LocalCopy%29.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m tqdm(get_training_dataset(train)):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/glebsokolov/Library/CloudStorage/GoogleDrive-yukontaf%40gmail.com/My%20Drive/%21HeadRepo/novozymesEnzymeStabilityPrediction%28LocalCopy%29.ipynb#X15sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m   predictions \u001b[39m=\u001b[39m regressor([batch[\u001b[39m0\u001b[39;49m], batch[\u001b[39m1\u001b[39;49m]], training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/glebsokolov/Library/CloudStorage/GoogleDrive-yukontaf%40gmail.com/My%20Drive/%21HeadRepo/novozymesEnzymeStabilityPrediction%28LocalCopy%29.ipynb#X15sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m   loss \u001b[39m=\u001b[39m loss_obj(batch[\u001b[39m2\u001b[39m], predictions)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/glebsokolov/Library/CloudStorage/GoogleDrive-yukontaf%40gmail.com/My%20Drive/%21HeadRepo/novozymesEnzymeStabilityPrediction%28LocalCopy%29.ipynb#X15sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m   losses\u001b[39m.\u001b[39mappend(loss)\n",
            "File \u001b[0;32m/Volumes/Environment/conda/miniconda3/envs/defaultenv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "\u001b[1;32m/Users/glebsokolov/Library/CloudStorage/GoogleDrive-yukontaf@gmail.com/My Drive/!HeadRepo/novozymesEnzymeStabilityPrediction(LocalCopy).ipynb Cell 13\u001b[0m in \u001b[0;36mMyModel.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/glebsokolov/Library/CloudStorage/GoogleDrive-yukontaf%40gmail.com/My%20Drive/%21HeadRepo/novozymesEnzymeStabilityPrediction%28LocalCopy%29.ipynb#X15sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m seq, ph \u001b[39m=\u001b[39m inputs\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/glebsokolov/Library/CloudStorage/GoogleDrive-yukontaf%40gmail.com/My%20Drive/%21HeadRepo/novozymesEnzymeStabilityPrediction%28LocalCopy%29.ipynb#X15sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m SEQ_LAYER_0 \u001b[39m=\u001b[39m \u001b[39mvars\u001b[39m(\u001b[39mself\u001b[39m)[\u001b[39m'\u001b[39m\u001b[39mSEQ_LAYER_0\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/glebsokolov/Library/CloudStorage/GoogleDrive-yukontaf%40gmail.com/My%20Drive/%21HeadRepo/novozymesEnzymeStabilityPrediction%28LocalCopy%29.ipynb#X15sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m x \u001b[39m=\u001b[39m SEQ_LAYER_0(seq)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/glebsokolov/Library/CloudStorage/GoogleDrive-yukontaf%40gmail.com/My%20Drive/%21HeadRepo/novozymesEnzymeStabilityPrediction%28LocalCopy%29.ipynb#X15sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm_layers):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/glebsokolov/Library/CloudStorage/GoogleDrive-yukontaf%40gmail.com/My%20Drive/%21HeadRepo/novozymesEnzymeStabilityPrediction%28LocalCopy%29.ipynb#X15sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     SEQ_LAYER_i \u001b[39m=\u001b[39m \u001b[39mvars\u001b[39m(\u001b[39mself\u001b[39m)[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSEQ_LAYER_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m]\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer \"embedding\" \"                 f\"(type Embedding).\n\n{{function_node __wrapped__ResourceGather_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[199,2250] = 49 is not in [0, 21) [Op:ResourceGather]\n\nCall arguments received by layer \"embedding\" \"                 f\"(type Embedding):\n  • inputs=tf.Tensor(shape=(256, 2251), dtype=float32)"
          ]
        }
      ],
      "source": [
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=100)\n",
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "989AAezAxUYK",
        "outputId": "e9b85b1e-610d-42d3-a345-e69021bbb7e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'Best trial:'\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "FrozenTrial(number=0, values=[9.231255531311035], datetime_start=datetime.datetime(2022, 10, 2, 2, 45, 57, 884555), datetime_complete=datetime.datetime(2022, 10, 2, 2, 50, 0, 948796), params={'lstm_layers': 5, 'emb_dim': 516, 'optimizer': <class 'keras.optimizer_v2.adamax.Adamax'>, 'learning_rate': 0.0003657022606919054, 'lstm_units_l0': 144, 'lstm_units_l1': 487, 'lstm_units_l2': 180, 'lstm_units_l3': 435, 'lstm_units_l4': 282, 'dropout_rate': 0.6139876507248502}, distributions={'lstm_layers': IntDistribution(high=7, log=False, low=1, step=1), 'emb_dim': IntDistribution(high=1024, log=False, low=8, step=1), 'optimizer': CategoricalDistribution(choices=(<class 'keras.optimizer_v2.adagrad.Adagrad'>, <class 'keras.optimizer_v2.adadelta.Adadelta'>, <class 'keras.optimizer_v2.adam.Adam'>, <class 'keras.optimizer_v2.adamax.Adamax'>, <class 'keras.optimizer_v2.ftrl.Ftrl'>, <class 'keras.optimizer_v2.nadam.Nadam'>, <class 'keras.optimizer_v2.gradient_descent.SGD'>, <class 'keras.optimizer_v2.rmsprop.RMSprop'>)), 'learning_rate': FloatDistribution(high=1.0, log=True, low=1e-07, step=None), 'lstm_units_l0': IntDistribution(high=512, log=False, low=16, step=1), 'lstm_units_l1': IntDistribution(high=512, log=False, low=16, step=1), 'lstm_units_l2': IntDistribution(high=512, log=False, low=16, step=1), 'lstm_units_l3': IntDistribution(high=512, log=False, low=16, step=1), 'lstm_units_l4': IntDistribution(high=512, log=False, low=16, step=1), 'dropout_rate': FloatDistribution(high=1.0, log=False, low=0.0, step=None)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=0, state=TrialState.COMPLETE, value=None)"
            ]
          },
          "execution_count": 389,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "trial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(32, 64), dtype=float32, numpy=\n",
              "array([[ 0.00255172, -0.00038243, -0.00433107, ...,  0.01631568,\n",
              "         0.01245562, -0.0166873 ],\n",
              "       [ 0.0037646 , -0.00017282, -0.00468532, ...,  0.0158443 ,\n",
              "         0.0121361 , -0.01649837],\n",
              "       [-0.00053325, -0.0007604 , -0.0038455 , ...,  0.01778299,\n",
              "         0.01330473, -0.01690527],\n",
              "       ...,\n",
              "       [ 0.00970213,  0.00063291, -0.00561702, ...,  0.01281975,\n",
              "         0.0099871 , -0.01621926],\n",
              "       [ 0.00050922, -0.0005741 , -0.00392779, ...,  0.01714535,\n",
              "         0.0130352 , -0.01674676],\n",
              "       [ 0.01195663,  0.001212  , -0.00619053, ...,  0.01121793,\n",
              "         0.00945734, -0.01510749]], dtype=float32)>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for i in get_training_dataset(train).take(1):\n",
        "    x = Embedding(vocab_size + 1, 2250)(i[0])\n",
        "    x = Conv1D(filters=64, kernel_size=5, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Conv1D(filters=64, kernel_size=3, activation='relu')(x)\n",
        "    x = Bidirectional(LSTM(32, return_sequences=True))(x)\n",
        "    x = GlobalAveragePooling1D()(x)\n",
        "    x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %pdb\n",
        "class MyModel2(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(MyModel2, self).__init__()\n",
        "    self.emb_dim, self.dropout_rate = 2250, 0.2\n",
        "    self.input_ph = tf.keras.layers.Input((1,))\n",
        "    self.input_seq = tf.keras.layers.Input((2251, ))\n",
        "    self.seq_layers =  [] \n",
        "    self.seq_layers.extend([\n",
        "                        Embedding(vocab_size + 1, self.emb_dim, name='embedding'),\n",
        "                        Conv1D(filters=64, kernel_size=5, activation='relu'),\n",
        "                        Dropout(self.dropout_rate),  \n",
        "                        Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
        "                        Dropout(self.dropout_rate),\n",
        "                        # Bidirectional(LSTM(2048, return_sequences=True, name='LSTM_1')),\n",
        "                        # Dropout(self.dropout_rate),\n",
        "                        # LSTM(1024, return_sequences=True, name='LSTM_2'),\n",
        "                        # LSTM(512, return_sequences=True, name='LSTM_3'),\n",
        "                        Bidirectional(LSTM(256, return_sequences=True, name='LSTM_4')),\n",
        "                        Dropout(self.dropout_rate),\n",
        "                        Bidirectional(LSTM(128, return_sequences=True, name='LSTM_5')),\n",
        "                        Dropout(self.dropout_rate),\n",
        "                        # tf.keras.layers.LSTM(64, return_sequences=True, name='LSTM_6'),\n",
        "                        Bidirectional(LSTM(32, return_sequences=True, name='LSTM_7')),\n",
        "                        Dropout(self.dropout_rate),\n",
        "                        Bidirectional(LSTM(16, return_sequences=True)),\n",
        "                        GlobalAveragePooling1D(),\n",
        "                        ])\n",
        "    for i in range(len(self.seq_layers)):\n",
        "      vars(self)[f'SEQ_LAYER_{i}'] = self.seq_layers[i]\n",
        "\n",
        "    self.ph_layers = [\n",
        "                      tf.keras.layers.Dense(512, name='dense1_ph', activation='relu'),\n",
        "                      tf.keras.layers.Dropout(self.dropout_rate), \n",
        "                      # tf.keras.layers.Dense(256, name='dense2_ph', activation='relu'),\n",
        "                      # tf.keras.layers.Dropout(self.dropout_rate), \n",
        "                      tf.keras.layers.Dense(128, name='dense3_ph', activation='relu'),\n",
        "                      tf.keras.layers.Dropout(self.dropout_rate),  \n",
        "                      tf.keras.layers.Dense(1, name='output_ph')\n",
        "                      ]\n",
        "\n",
        "    self.lambda_layer = Lambda(function=concat, name='lambda_layer')\n",
        "    self.flatten = Flatten(name='flatten')\n",
        "    self.dense_combined = Dense(64, activation='relu', name='dense_combined')\n",
        "    self.lambda_helper = Lambda(lambda x: tf.reshape(x, (-1, 64, 1)))\n",
        "    self.last_dense = Dense(1, activation='relu', name='output')\n",
        "\n",
        "  def call(self, inputs):\n",
        "    seq, ph = inputs\n",
        "\n",
        "    for layer in self.seq_layers:\n",
        "      seq = layer(seq)\n",
        "\n",
        "    for layer in self.ph_layers:\n",
        "      ph = layer(ph)\n",
        "\n",
        "    x = self.lambda_layer([seq, ph])\n",
        "    x = self.flatten(x)\n",
        "    x = self.dense_combined(x)\n",
        "    x = self.lambda_helper(x)\n",
        "    x = self.last_dense(x)\n",
        "    return x\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "t6JB2_gWxUZW"
      },
      "outputs": [],
      "source": [
        "model = MyModel2()\n",
        "adam, SGD_fn, rms = Adam(1e-3), SGD(1e-4), RMSprop(1e-4)\n",
        "loss_fn = MeanAbsoluteError()\n",
        "model.compile(optimizer=adam, loss=loss_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch # 0 started\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 3/785 [01:38<7:07:41, 32.82s/it]\n"
          ]
        },
        {
          "ename": "InvalidArgumentError",
          "evalue": "Exception encountered when calling layer \"embedding\" \"                 f\"(type Embedding).\n\n{{function_node __wrapped__ResourceGather_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[20,2250] = 48 is not in [0, 21) [Op:ResourceGather]\n\nCall arguments received by layer \"embedding\" \"                 f\"(type Embedding):\n  • inputs=tf.Tensor(shape=(32, 2251), dtype=float32)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[1;32m/Users/glebsokolov/Library/CloudStorage/GoogleDrive-yukontaf@gmail.com/My Drive/!HeadRepo/novozymesEnzymeStabilityPrediction(LocalCopy).ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/glebsokolov/Library/CloudStorage/GoogleDrive-yukontaf%40gmail.com/My%20Drive/%21HeadRepo/novozymesEnzymeStabilityPrediction%28LocalCopy%29.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch # \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m started\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/glebsokolov/Library/CloudStorage/GoogleDrive-yukontaf%40gmail.com/My%20Drive/%21HeadRepo/novozymesEnzymeStabilityPrediction%28LocalCopy%29.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m tqdm(get_training_dataset(train)):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/glebsokolov/Library/CloudStorage/GoogleDrive-yukontaf%40gmail.com/My%20Drive/%21HeadRepo/novozymesEnzymeStabilityPrediction%28LocalCopy%29.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     predictions \u001b[39m=\u001b[39m model([batch[\u001b[39m0\u001b[39;49m], batch[\u001b[39m1\u001b[39;49m]], training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/glebsokolov/Library/CloudStorage/GoogleDrive-yukontaf%40gmail.com/My%20Drive/%21HeadRepo/novozymesEnzymeStabilityPrediction%28LocalCopy%29.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(batch[\u001b[39m2\u001b[39m], predictions)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/glebsokolov/Library/CloudStorage/GoogleDrive-yukontaf%40gmail.com/My%20Drive/%21HeadRepo/novozymesEnzymeStabilityPrediction%28LocalCopy%29.ipynb#X25sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m# print(tf.math.reduce_mean(loss))\u001b[39;00m\n",
            "File \u001b[0;32m/Volumes/Environment/conda/miniconda3/envs/defaultenv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "\u001b[1;32m/Users/glebsokolov/Library/CloudStorage/GoogleDrive-yukontaf@gmail.com/My Drive/!HeadRepo/novozymesEnzymeStabilityPrediction(LocalCopy).ipynb Cell 17\u001b[0m in \u001b[0;36mMyModel2.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/glebsokolov/Library/CloudStorage/GoogleDrive-yukontaf%40gmail.com/My%20Drive/%21HeadRepo/novozymesEnzymeStabilityPrediction%28LocalCopy%29.ipynb#X25sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m seq, ph \u001b[39m=\u001b[39m inputs\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/glebsokolov/Library/CloudStorage/GoogleDrive-yukontaf%40gmail.com/My%20Drive/%21HeadRepo/novozymesEnzymeStabilityPrediction%28LocalCopy%29.ipynb#X25sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseq_layers:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/glebsokolov/Library/CloudStorage/GoogleDrive-yukontaf%40gmail.com/My%20Drive/%21HeadRepo/novozymesEnzymeStabilityPrediction%28LocalCopy%29.ipynb#X25sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m   seq \u001b[39m=\u001b[39m layer(seq)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/glebsokolov/Library/CloudStorage/GoogleDrive-yukontaf%40gmail.com/My%20Drive/%21HeadRepo/novozymesEnzymeStabilityPrediction%28LocalCopy%29.ipynb#X25sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mph_layers:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/glebsokolov/Library/CloudStorage/GoogleDrive-yukontaf%40gmail.com/My%20Drive/%21HeadRepo/novozymesEnzymeStabilityPrediction%28LocalCopy%29.ipynb#X25sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m   ph \u001b[39m=\u001b[39m layer(ph)\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer \"embedding\" \"                 f\"(type Embedding).\n\n{{function_node __wrapped__ResourceGather_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[20,2250] = 48 is not in [0, 21) [Op:ResourceGather]\n\nCall arguments received by layer \"embedding\" \"                 f\"(type Embedding):\n  • inputs=tf.Tensor(shape=(32, 2251), dtype=float32)"
          ]
        }
      ],
      "source": [
        "# %pdb\n",
        "for epoch in range(10):\n",
        "    print(f'Epoch # {epoch} started')\n",
        "    for batch in tqdm(get_training_dataset(train)):\n",
        "        predictions = model([batch[0], batch[1]], training=True)\n",
        "        loss = loss_fn(batch[2], predictions)\n",
        "        # print(tf.math.reduce_mean(loss))\n",
        "    for val_batch in tqdm(get_validation_dataset(val)):\n",
        "        predictions = model([val_batch[0], val_batch[1]], training=False)\n",
        "        val_loss = loss_fn(val_batch[2], predictions)\n",
        "    print(f'Validation Loss {tf.math.reduce_mean(val_loss):.2f}')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('defaultenv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "c1d7054af77ba560f87b9c7884b1cfb54f44503b6d572a00787a3ee06861aa5a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
