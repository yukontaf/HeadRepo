{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yukontaf/HeadRepo/blob/main/novozymesEnzymeStabilityPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "DqvAfHXqxUYC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd, numpy as np, matplotlib.pyplot as plt, matplotlib\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import os\n",
        "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "# os.environ['TF_ENABLE_ONEDNN_OPTS'] = '1'\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.losses import MeanAbsoluteError\n",
        "from tensorflow.keras.optimizers import Adagrad, Adadelta, Adam, Adamax, Ftrl, Nadam, SGD, RMSprop \n",
        "from tqdm import tqdm\n",
        "matplotlib.style.use(\"seaborn-whitegrid\")\n",
        "pd.set_option(\"display.width\", 5000)\n",
        "pd.set_option(\"display.max_columns\", 60)\n",
        "plt.rcParams[\"figure.figsize\"] = (15, 10)\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
        "AUTO = tf.data.experimental.AUTOTUNE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install optuna\n",
        "!pip install ipdb"
      ],
      "metadata": {
        "id": "Xu6m1iQkcdRa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"TF_MIN_GPU_MULTIPROCESSOR_COUNT\"] = \"1\"\n",
        "strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n",
        "print ('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rVfnE71n7cO",
        "outputId": "2dc505d4-dc92-4af0-d30f-bd8a3a8cfd57"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of devices: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import ipdb\n",
        "from optuna.trial import TrialState"
      ],
      "metadata": {
        "id": "LCwoZ9JT4sk8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 12ceraaz41xJ503VhZlU-WnBB5pR8QWWf\n",
        "!gdown 1mocZNvYWzWL9U-kygm9QU4ejuJoO0jyo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUvW033axX0I",
        "outputId": "1fa1eb45-eab8-4e9f-c4de-b33664108b4a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12ceraaz41xJ503VhZlU-WnBB5pR8QWWf\n",
            "To: /content/train.feather\n",
            "100% 12.2M/12.2M [00:00<00:00, 224MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1mocZNvYWzWL9U-kygm9QU4ejuJoO0jyo\n",
            "To: /content/test.feather\n",
            "100% 45.8k/45.8k [00:00<00:00, 63.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_feather('/content/train.feather')\n",
        "df = df.drop('data_source', axis=1)\n",
        "df = df.fillna(0)\n",
        "train = df.sample(frac = 0.8)\n",
        "val = df.drop(train.index, axis=0)"
      ],
      "metadata": {
        "id": "OdJ_ise1qMPY"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "VjpEHcvlxUYI"
      },
      "outputs": [],
      "source": [
        "def split_seq(df):\n",
        "    sentences = np.array([\n",
        "    df[['protein_sequence']].to_numpy()[:, 0],\n",
        "])\n",
        "    splitted= []\n",
        "    for i in sentences[0, :]:\n",
        "        splitted.append(list(i))\n",
        "\n",
        "    return np.array(splitted)\n",
        "\n",
        "train_seq, test_seq = split_seq(train), split_seq(val)\n",
        "\n",
        "train_ph, val_ph = train['pH'].to_numpy().reshape((len(train), 1)), val['pH'].to_numpy().reshape((len(val), 1))\n",
        "train_tm, val_tm = train['tm'].to_numpy().reshape((len(train), 1)), val['tm'].to_numpy().reshape((len(val), 1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['protein_sequence'].apply(lambda x: len(x)).quantile(0.99)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ro80MZB2ZMm",
        "outputId": "b8c5ba33-d367-4c76-8279-ddfb4be125d7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2223.0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Q4Bd-xxfxUYJ"
      },
      "outputs": [],
      "source": [
        "max_length = 2255\n",
        "trunc_type='post'\n",
        "embedding_dim = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "tdNq9IJfxUYJ"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_seq)\n",
        "sequences = tokenizer.texts_to_sequences(train_seq)\n",
        "padded = pad_sequences(sequences, maxlen=max_length, truncating=trunc_type)\n",
        "vocab_size = len(tokenizer.word_index)\n",
        "train = tf.data.Dataset.from_tensor_slices(np.append(np.append(padded, train_ph, 1), train_tm, 1))\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(test_seq)\n",
        "testing_padded = pad_sequences(testing_sequences,maxlen=max_length)\n",
        "val = tf.data.Dataset.from_tensor_slices(np.append(np.append(testing_padded, val_ph, 1), val_tm, 1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 256\n",
        "def preprocess(data):\n",
        "    sequence = data[:-1]\n",
        "    ph = tf.reshape(data[-2], (-1, ))\n",
        "    tm = data[-1]\n",
        "    return sequence, ph, tm\n",
        "def get_training_dataset(dataset):\n",
        "    dataset = dataset.map(preprocess).shuffle(len(sequences)).batch(BATCH_SIZE)\n",
        "    return dataset\n",
        "def get_validation_dataset(valid):\n",
        "  valid = valid.map(preprocess).shuffle(len(sequences)).batch(BATCH_SIZE)\n",
        "  return valid\n",
        "def concat(input):\n",
        "  return tf.concat([input[0], input[1]], -1)\n",
        "  # return tf.keras.layers.concatenate([input[0], input[1]], axis=1)"
      ],
      "metadata": {
        "id": "lo0y5tvepgqc"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %pdb\n",
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, lstm_layers, emb_dim, lstm_units, dropout_rate):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.lstm_layers, self.emb_dim, self.lstm_units, self.dropout_rate = lstm_layers, emb_dim, lstm_units, dropout_rate\n",
        "    self.input_ph = tf.keras.layers.Input((1,))\n",
        "    self.input_seq = tf.keras.layers.Input((500, ))\n",
        "    seq_layers =  [] \n",
        "    seq_layers.extend([tf.keras.layers.Embedding(21, emb_dim, name='embedding'),\n",
        "                        tf.keras.layers.Conv1D(filters=128, kernel_size=5, activation='relu'),\n",
        "                        tf.keras.layers.Dropout(dropout_rate),  \n",
        "                        tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
        "                        tf.keras.layers.Dropout(dropout_rate),\n",
        "                        *[tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(i, return_sequences=True, name=f'LSTM_{i}')) for j in range(lstm_layers-1) for i in lstm_units],\n",
        "                        ])\n",
        "    for i in range(len(seq_layers)):\n",
        "      vars(self)[f'SEQ_LAYER_{i}'] = seq_layers[i]\n",
        "\n",
        "    self.ph_layers = [\n",
        "                      tf.keras.layers.Dense(512, name='dense1_ph', activation='relu'),\n",
        "                      tf.keras.layers.Dropout(dropout_rate), \n",
        "                      tf.keras.layers.Dense(256, name='dense2_ph', activation='relu'),\n",
        "                      tf.keras.layers.Dropout(dropout_rate), \n",
        "                      tf.keras.layers.Dense(128, name='dense3_ph', activation='relu'),\n",
        "                      tf.keras.layers.Dropout(dropout_rate),  \n",
        "                      tf.keras.layers.Dense(1, name='output_ph')\n",
        "                      ]\n",
        "\n",
        "    self.lambda_layer = tf.keras.layers.Lambda(function=concat, name='lambda_layer')\n",
        "    self.flatten = tf.keras.layers.Flatten(name='flatten')\n",
        "    self.dense_combined = tf.keras.layers.Dense(64, activation='relu', name='dense_combined')\n",
        "    self.lambda_helper = tf.keras.layers.Lambda(lambda x: tf.reshape(x, (-1, 64, 1)))\n",
        "    self.lstm_dense = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(512))\n",
        "    self.last_dense = tf.keras.layers.Dense(1, name='output')\n",
        "\n",
        "  def call(self, inputs):\n",
        "    seq, ph = inputs\n",
        "    SEQ_LAYER_0 = vars(self)['SEQ_LAYER_0']\n",
        "    x = SEQ_LAYER_0(seq)\n",
        "    for i in range(1, self.lstm_layers):\n",
        "        SEQ_LAYER_i = vars(self)[f'SEQ_LAYER_{i}']\n",
        "        x = SEQ_LAYER_i(x)\n",
        "    for ind, layer in enumerate(self.ph_layers):\n",
        "      ph = layer(ph)\n",
        "    x = self.lambda_layer([seq, ph])\n",
        "    x = self.flatten(x)\n",
        "    x = self.dense_combined(x)\n",
        "    x = self.lambda_helper(x)\n",
        "    x = self.lstm_dense(x)\n",
        "    x = self.last_dense(x)\n",
        "    return x\n",
        "    "
      ],
      "metadata": {
        "id": "w3JlzGcFePL-"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_STEPS = 15\n",
        "PRUNING_INTERVAL_STEPS = 50\n",
        "def objective(trial):    \n",
        "  lstm_layers = trial.suggest_int('lstm_layers', 1, 7)\n",
        "  emb_dim = trial.suggest_int('emb_dim', 256, 1024)\n",
        "  lstm_units = []\n",
        "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-7, 1)\n",
        "  for i in range(lstm_layers):\n",
        "    lstm_units.append(trial.suggest_int(f'lstm_units_l{i}', 16, 512))\n",
        "  dropout_rate = trial.suggest_uniform('dropout_rate', 0, 1)\n",
        "  optimizer = trial.suggest_categorical('optimizer', [Adagrad, Adadelta, Adam, Adamax, Ftrl, Nadam, SGD, RMSprop])\n",
        "  regressor = MyModel(lstm_layers, emb_dim, lstm_units, dropout_rate)\n",
        "  loss_obj = tf.keras.metrics.MeanAbsoluteError(name='loss_obj')\n",
        "  regressor.compile(loss=loss_obj, optimizer=optimizer(learning_rate=learning_rate))\n",
        "  for epoch in range(10):\n",
        "    print(f'Epoch # {epoch} started')\n",
        "    for batch in tqdm(get_training_dataset(train)):\n",
        "      predictions = regressor([batch[0], batch[1]], training=True)\n",
        "      loss = loss_obj(batch[2], predictions)\n",
        "    print(f'Training Loss {loss}')\n",
        "    for val_batch in tqdm(get_validation_dataset(val)):\n",
        "      predictions = regressor([val_batch[0], val_batch[1]], training=False)\n",
        "      val_loss = loss_obj(val_batch[2], predictions)\n",
        "    print(f'Validation Loss {val_loss}')\n",
        "  return val_loss"
      ],
      "metadata": {
        "id": "CM324baOeGHf"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=100)\n",
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELrn1aBzLs2P",
        "outputId": "aa53294d-5fcb-45dd-ca3a-ee0c888afc3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-10-02 04:26:08,944]\u001b[0m A new study created in memory with name: no-name-4ca143c8-15c6-476a-88e5-5cec432e4e27\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch # 0 started\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 99/99 [01:14<00:00,  1.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss 49.242759704589844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [00:17<00:00,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss 49.19940948486328\n",
            "Epoch # 1 started\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 7/99 [00:05<01:09,  1.32it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "989AAezAxUYK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9b85b1e-610d-42d3-a345-e69021bbb7e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Best trial:'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FrozenTrial(number=0, values=[9.231255531311035], datetime_start=datetime.datetime(2022, 10, 2, 2, 45, 57, 884555), datetime_complete=datetime.datetime(2022, 10, 2, 2, 50, 0, 948796), params={'lstm_layers': 5, 'emb_dim': 516, 'optimizer': <class 'keras.optimizer_v2.adamax.Adamax'>, 'learning_rate': 0.0003657022606919054, 'lstm_units_l0': 144, 'lstm_units_l1': 487, 'lstm_units_l2': 180, 'lstm_units_l3': 435, 'lstm_units_l4': 282, 'dropout_rate': 0.6139876507248502}, distributions={'lstm_layers': IntDistribution(high=7, log=False, low=1, step=1), 'emb_dim': IntDistribution(high=1024, log=False, low=8, step=1), 'optimizer': CategoricalDistribution(choices=(<class 'keras.optimizer_v2.adagrad.Adagrad'>, <class 'keras.optimizer_v2.adadelta.Adadelta'>, <class 'keras.optimizer_v2.adam.Adam'>, <class 'keras.optimizer_v2.adamax.Adamax'>, <class 'keras.optimizer_v2.ftrl.Ftrl'>, <class 'keras.optimizer_v2.nadam.Nadam'>, <class 'keras.optimizer_v2.gradient_descent.SGD'>, <class 'keras.optimizer_v2.rmsprop.RMSprop'>)), 'learning_rate': FloatDistribution(high=1.0, log=True, low=1e-07, step=None), 'lstm_units_l0': IntDistribution(high=512, log=False, low=16, step=1), 'lstm_units_l1': IntDistribution(high=512, log=False, low=16, step=1), 'lstm_units_l2': IntDistribution(high=512, log=False, low=16, step=1), 'lstm_units_l3': IntDistribution(high=512, log=False, low=16, step=1), 'lstm_units_l4': IntDistribution(high=512, log=False, low=16, step=1), 'dropout_rate': FloatDistribution(high=1.0, log=False, low=0.0, step=None)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=0, state=TrialState.COMPLETE, value=None)"
            ]
          },
          "metadata": {},
          "execution_count": 389
        }
      ],
      "source": [
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "trial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6JB2_gWxUZW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.13 ('defaultenv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "c1d7054af77ba560f87b9c7884b1cfb54f44503b6d572a00787a3ee06861aa5a"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}