{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from pprint import pprint as print\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-white')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from navec import Navec\n",
    "from slovnet.model.emb import NavecEmbedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from loguru import logger\n",
    "import nltk, sys\n",
    "from stop_words import get_stop_words\n",
    "from pymystem3 import Mystem\n",
    "from string import punctuation\n",
    "from loguru import logger\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_models as tfm\n",
    "import os\n",
    "import tensorflow_text as text\n",
    "sns.set_palette(\"pastel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1boACz8ab9UytCpi0QhTUFRyS2oyH1MXS\n",
      "To: /Users/glebsokolov/HeadRepo/test_data.csv\n",
      "100%|██████████████████████████████████████| 53.4k/53.4k [00:00<00:00, 1.04MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown 1boACz8ab9UytCpi0QhTUFRyS2oyH1MXS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/glebsokolov/HeadRepo/navec_hudlit_v1_12B_500K_300d_100q.tar'\n",
    "navec = Navec.load(path)\n",
    "emb = NavecEmbedding(navec)\n",
    "cosine_similarity = lambda x,y: np.dot(x, y)/(np.linalg.norm(x, 2)*np.linalg.norm(y, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_calc(vec_1,vec_2):\n",
    "\tsim = np.dot(vec_1,vec_2)/(np.linalg.norm(vec_1)*np.linalg.norm(vec_2))\n",
    "\treturn sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORDS = 1000\n",
    "EMBEDDING_DIM = 300\n",
    "MAXLEN = 120\n",
    "PADDING = 'post'\n",
    "OOV_TOKEN = \"<OOV>\"\n",
    "TRAINING_SPLIT = .8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem = Mystem()\n",
    "russian_stopwords = get_stop_words('ru')\n",
    "def preprocess_text(text):\n",
    "    tokens = mystem.lemmatize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in russian_stopwords\\\n",
    "              and token != \" \" \\\n",
    "              and token.strip() not in punctuation]\n",
    "    \n",
    "    text = \" \".join(tokens)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dlg_id</th>\n",
       "      <th>line_n</th>\n",
       "      <th>role</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>client</td>\n",
       "      <td>Алло</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>manager</td>\n",
       "      <td>Алло здравствуйте</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>client</td>\n",
       "      <td>Добрый день</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>manager</td>\n",
       "      <td>Меня зовут ангелина компания диджитал бизнес з...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>client</td>\n",
       "      <td>Ага</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dlg_id  line_n     role                                               text\n",
       "0       0       0   client                                               Алло\n",
       "1       0       1  manager                                  Алло здравствуйте\n",
       "2       0       2   client                                        Добрый день\n",
       "3       0       3  manager  Меня зовут ангелина компания диджитал бизнес з...\n",
       "4       0       4   client                                                Ага"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'The length of dataframe is 480'\n",
      "'There are 5 dialogues in there.'\n"
     ]
    }
   ],
   "source": [
    "path='/Users/glebsokolov/HeadRepo/test_data.csv'\n",
    "df = pd.read_csv(path)\n",
    "df.head()\n",
    "print(f'The length of dataframe is {len(df)}')\n",
    "print(f'There are {max(df.dlg_id)} dialogues in there.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'The shape of the cleared dataframe is:(424,)'\n",
      "'Length of word index is 641'\n",
      "'The shape of padded sequences are (424, 120, 1)'\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words = NUM_WORDS, oov_token=OOV_TOKEN)\n",
    "texts_combined = [preprocess_text(i) for i in df.iloc[:,3]]\n",
    "texts_cleared = [i for i in texts_combined if i !='']\n",
    "print(f'The shape of the cleared dataframe is:{np.shape(texts_cleared)}')\n",
    "tokenizer.fit_on_texts(texts_cleared)\n",
    "word_index = tokenizer.word_index\n",
    "print(f'Length of word index is {len(tokenizer.word_index)}')\n",
    "sequence = lambda x: tokenizer.texts_to_sequences(x.split(' '))\n",
    "sequences = pad_sequences([sequence(x) for x in texts_cleared], maxlen=MAXLEN, padding=PADDING)\n",
    "print(f'The shape of padded sequences are {np.shape(sequences)}')\n",
    "# keyword = lambda x: [i for i in word_index if word_index[i]==x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([424, 120, 300])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.tensor([np.array(np.reshape(sequences[i],-1) )for i in range(len(texts_cleared))]).long()\n",
    "embedded = tf.convert_to_tensor(emb(input).numpy())\n",
    "np.shape(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "replies = [embedded[i,:,:] for i in range(len(texts_cleared))]\n",
    "def calculate_max_similarity(sentence1, sentence2=navec['здравствуйте']):\n",
    "    # find cosine similarity for each pair of words in the sentence\n",
    "    similarities = np.array([])\n",
    "    for ind in range(len(sentence1)):\n",
    "        similarities = np.append(similarities, cosine_similarity(sentence1[ind], sentence2))\n",
    "    return np.max(similarities)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = np.array([])\n",
    "for reply in replies:\n",
    "    similarities = np.append(similarities, calculate_max_similarity(reply))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    # tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('defaultenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1d7054af77ba560f87b9c7884b1cfb54f44503b6d572a00787a3ee06861aa5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
