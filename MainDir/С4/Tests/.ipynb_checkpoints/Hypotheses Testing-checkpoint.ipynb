{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c38f6b0e-3174-49af-ad69-d0a9ee23632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import bamboolib as bam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import snoop\n",
    "from IPython.core.debugger import set_trace\n",
    "from loguru import logger\n",
    "from statsmodels.stats.proportion import proportion_confint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed704edc-f7bf-4e6b-a76a-26a302603630",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0029ef91-12d8-4d22-aa28-65fac6ba8e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a43b88ff50f4146846ac79c110e6b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MitoWidget(analysis_data_json='{\"analysisName\": \"UUID-3fa7ad78-4d04-4c8b-8361-d03b0893a7c9\", \"code\": {\"imports…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mitosheet\n",
    "\n",
    "mitosheet.sheet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82a7aa65-44c5-4a8f-a1cf-1585476720bd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MITO CODE START (DO NOT EDIT)\n",
    "\n",
    "import pandas as pd\n",
    "from mitosheet import *  # Import necessary functions from Mito\n",
    "\n",
    "# Let Mito know which analysis is being run\n",
    "register_analysis(\"UUID-6ed7376a-70ab-46b6-bb0c-312bfee8a14e\")\n",
    "\n",
    "# Imported /Users/glebsokolov/MainDir/dataframes/adult.data.csv\n",
    "adult_data_csv = pd.read_csv(r\"/Users/glebsokolov/MainDir/dataframes/adult.data.csv\")\n",
    "\n",
    "# Pivoted adult_data_csv into df2\n",
    "unused_columns = adult_data_csv.columns.difference(\n",
    "    set([\"age\"]).union(set([\"workclass\"])).union(set({\"age\"}))\n",
    ")\n",
    "tmp_df = adult_data_csv.drop(unused_columns, axis=1)\n",
    "pivot_table = tmp_df.pivot_table(\n",
    "    index=[\"age\"], columns=[\"workclass\"], values=[\"age\"], aggfunc={\"age\": [\"count\"]}\n",
    ")\n",
    "\n",
    "# Flatten the column headers\n",
    "pivot_table.columns = [flatten_column_header(col) for col in pivot_table.columns.values]\n",
    "\n",
    "# Reset the column name and the indexes\n",
    "df2 = pivot_table.reset_index()\n",
    "\n",
    "\n",
    "# MITO CODE END (DO NOT EDIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09156f83-bc37-4d45-85f8-760e5574f43b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_7.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import plotly and create a figure\n",
    "import plotly.graph_objects as go\n",
    "from mitosheet import filter_df_to_safe_size\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "\n",
    "# Filter the dataframe so that it doesn't crash the browser with too much data\n",
    "adult_data_csv_filtered, _ = filter_df_to_safe_size(\n",
    "    \"scatter\", adult_data_csv, [\"workclass\", \"hours-per-week\"]\n",
    ")\n",
    "\n",
    "\n",
    "# Add the scatter traces to the figure\n",
    "for column_header in [\"workclass\"]:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=adult_data_csv_filtered[column_header],\n",
    "            y=adult_data_csv_filtered[\"hours-per-week\"],\n",
    "            mode=\"markers\",\n",
    "            name=column_header,\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Update the layout\n",
    "# See Plotly documentation for cutomizations: https://plotly.com/python/reference/scatter/\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"workclass\",\n",
    "    yaxis_title=\"hours-per-week\",\n",
    "    title=\"workclass, hours-per-week (first 10k) scatter plot\",\n",
    ")\n",
    "fig.show(renderer=\"iframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cc74572-36b6-4d4c-9d64-99187541152c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb72bdb1c0964c288b82d40530d41ffe"
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sn</th>\n",
       "      <th>we</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200.0</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199.3</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>193.6</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>167.7</td>\n",
       "      <td>35.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>183.9</td>\n",
       "      <td>45.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sn    we\n",
       "0  200.0   8.8\n",
       "1  199.3  10.0\n",
       "2  193.6  22.4\n",
       "3  167.7  35.6\n",
       "4  183.9  45.4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/glebsokolov/MainDir/С4/pines.txt\", sep=\"\\t\")\n",
    "df.head()\n",
    "# df.sort_values(by = ['sn', 'we'], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4644fc4d-c39b-4a32-8153-9c9ba3466fc8",
   "metadata": {},
   "source": [
    "Загрузите данные, поделите участок на 5х5 одинаковых квадратов размера 40x40 м, посчитайте количество сосен в каждом квадрате (чтобы получить такой же результат, как у нас, используйте функцию scipy.stats.binned_statistic_2d).\n",
    "\n",
    "Если сосны действительно растут равномерно, какое среднее ожидаемое количество сосен в каждом квадрате? В правильном ответе два знака после десятичной точки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2787fd00-cf05-4291-bc8e-577ffc7e9b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = df[\"sn\"].to_numpy(), df[\"we\"].to_numpy()\n",
    "stat = stats.binned_statistic_2d(x, y, None, \"count\", bins=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c743261a-9ffc-4cf6-a608-4f3c05f54abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.36"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.reshape(stat[0], (-1,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16abfba3-9d1b-4a6a-8187-971b2ae1f374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150.59"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(stats.chisquare(np.reshape(stat[0], (-1,)))[0], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0492970d-29fb-46ba-9c62-6b50f6043e16",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function chisquare in module scipy.stats.stats:\n",
      "\n",
      "chisquare(f_obs, f_exp=None, ddof=0, axis=0)\n",
      "    Calculate a one-way chi-square test.\n",
      "    \n",
      "    The chi-square test tests the null hypothesis that the categorical data\n",
      "    has the given frequencies.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    f_obs : array_like\n",
      "        Observed frequencies in each category.\n",
      "    f_exp : array_like, optional\n",
      "        Expected frequencies in each category.  By default the categories are\n",
      "        assumed to be equally likely.\n",
      "    ddof : int, optional\n",
      "        \"Delta degrees of freedom\": adjustment to the degrees of freedom\n",
      "        for the p-value.  The p-value is computed using a chi-squared\n",
      "        distribution with ``k - 1 - ddof`` degrees of freedom, where `k`\n",
      "        is the number of observed frequencies.  The default value of `ddof`\n",
      "        is 0.\n",
      "    axis : int or None, optional\n",
      "        The axis of the broadcast result of `f_obs` and `f_exp` along which to\n",
      "        apply the test.  If axis is None, all values in `f_obs` are treated\n",
      "        as a single data set.  Default is 0.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    chisq : float or ndarray\n",
      "        The chi-squared test statistic.  The value is a float if `axis` is\n",
      "        None or `f_obs` and `f_exp` are 1-D.\n",
      "    p : float or ndarray\n",
      "        The p-value of the test.  The value is a float if `ddof` and the\n",
      "        return value `chisq` are scalars.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    scipy.stats.power_divergence\n",
      "    scipy.stats.fisher_exact : Fisher exact test on a 2x2 contingency table.\n",
      "    scipy.stats.barnard_exact : An unconditional exact test. An alternative\n",
      "        to chi-squared test for small sample sizes.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    This test is invalid when the observed or expected frequencies in each\n",
      "    category are too small.  A typical rule is that all of the observed\n",
      "    and expected frequencies should be at least 5. According to [3]_, the\n",
      "    total number of samples is recommended to be greater than 13,\n",
      "    otherwise exact tests (such as Barnard's Exact test) should be used\n",
      "    because they do not overreject.\n",
      "    \n",
      "    Also, the sum of the observed and expected frequencies must be the same\n",
      "    for the test to be valid; `chisquare` raises an error if the sums do not\n",
      "    agree within a relative tolerance of ``1e-8``.\n",
      "    \n",
      "    The default degrees of freedom, k-1, are for the case when no parameters\n",
      "    of the distribution are estimated. If p parameters are estimated by\n",
      "    efficient maximum likelihood then the correct degrees of freedom are\n",
      "    k-1-p. If the parameters are estimated in a different way, then the\n",
      "    dof can be between k-1-p and k-1. However, it is also possible that\n",
      "    the asymptotic distribution is not chi-square, in which case this test\n",
      "    is not appropriate.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] Lowry, Richard.  \"Concepts and Applications of Inferential\n",
      "           Statistics\". Chapter 8.\n",
      "           https://web.archive.org/web/20171022032306/http://vassarstats.net:80/textbook/ch8pt1.html\n",
      "    .. [2] \"Chi-squared test\", https://en.wikipedia.org/wiki/Chi-squared_test\n",
      "    .. [3] Pearson, Karl. \"On the criterion that a given system of deviations from the probable\n",
      "           in the case of a correlated system of variables is such that it can be reasonably\n",
      "           supposed to have arisen from random sampling\", Philosophical Magazine. Series 5. 50\n",
      "           (1900), pp. 157-175.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    When just `f_obs` is given, it is assumed that the expected frequencies\n",
      "    are uniform and given by the mean of the observed frequencies.\n",
      "    \n",
      "    >>> from scipy.stats import chisquare\n",
      "    >>> chisquare([16, 18, 16, 14, 12, 12])\n",
      "    (2.0, 0.84914503608460956)\n",
      "    \n",
      "    With `f_exp` the expected frequencies can be given.\n",
      "    \n",
      "    >>> chisquare([16, 18, 16, 14, 12, 12], f_exp=[16, 16, 16, 16, 16, 8])\n",
      "    (3.5, 0.62338762774958223)\n",
      "    \n",
      "    When `f_obs` is 2-D, by default the test is applied to each column.\n",
      "    \n",
      "    >>> obs = np.array([[16, 18, 16, 14, 12, 12], [32, 24, 16, 28, 20, 24]]).T\n",
      "    >>> obs.shape\n",
      "    (6, 2)\n",
      "    >>> chisquare(obs)\n",
      "    (array([ 2.        ,  6.66666667]), array([ 0.84914504,  0.24663415]))\n",
      "    \n",
      "    By setting ``axis=None``, the test is applied to all data in the array,\n",
      "    which is equivalent to applying the test to the flattened array.\n",
      "    \n",
      "    >>> chisquare(obs, axis=None)\n",
      "    (23.31034482758621, 0.015975692534127565)\n",
      "    >>> chisquare(obs.ravel())\n",
      "    (23.31034482758621, 0.015975692534127565)\n",
      "    \n",
      "    `ddof` is the change to make to the default degrees of freedom.\n",
      "    \n",
      "    >>> chisquare([16, 18, 16, 14, 12, 12], ddof=1)\n",
      "    (2.0, 0.73575888234288467)\n",
      "    \n",
      "    The calculation of the p-values is done by broadcasting the\n",
      "    chi-squared statistic with `ddof`.\n",
      "    \n",
      "    >>> chisquare([16, 18, 16, 14, 12, 12], ddof=[0,1,2])\n",
      "    (2.0, array([ 0.84914504,  0.73575888,  0.5724067 ]))\n",
      "    \n",
      "    `f_obs` and `f_exp` are also broadcast.  In the following, `f_obs` has\n",
      "    shape (6,) and `f_exp` has shape (2, 6), so the result of broadcasting\n",
      "    `f_obs` and `f_exp` has shape (2, 6).  To compute the desired chi-squared\n",
      "    statistics, we use ``axis=1``:\n",
      "    \n",
      "    >>> chisquare([16, 18, 16, 14, 12, 12],\n",
      "    ...           f_exp=[[16, 16, 16, 16, 16, 8], [8, 20, 20, 16, 12, 12]],\n",
      "    ...           axis=1)\n",
      "    (array([ 3.5 ,  9.25]), array([ 0.62338763,  0.09949846]))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(stats.chisquare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bbc68fe-dc1b-4360-a09f-ff6fb03468bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.weightstats import _tconfint_generic, _zconfint_generic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4f0f5e-4711-4abf-af1f-b804974c40ea",
   "metadata": {},
   "source": [
    "По данным опроса, 75% работников ресторанов утверждают, что испытывают на работе существенный стресс, оказывающий негативное влияние на их личную жизнь. Крупная ресторанная сеть опрашивает 100 своих работников, чтобы выяснить, отличается ли уровень стресса работников в их ресторанах от среднего. 67 из 100 работников отметили высокий уровень стресса. \n",
    "\n",
    "Посчитайте достигаемый уровень значимости, округлите ответ до четырёх знаков после десятичной точки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7ab835-cc43-44c6-93c1-8fe6a281f020",
   "metadata": {},
   "source": [
    "$$\\begin{aligned}\n",
    "Z\\left(X^{n}\\right) &=\\frac{\\hat{p}-p_{0}}{\\sqrt{\\frac{p_{0}\\left(1-p_{0}\\right)}{n}}}, \\hat{p}=\\bar{X}_{n} \\\\\n",
    "Z\\left(X^{n}\\right) & \\sim N(0,1)\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f69dc9-4cc6-4d0b-9441-0af81212b5e2",
   "metadata": {},
   "source": [
    "$\\bar{X}_n = 0.67$\\\n",
    "$p_0=0.75$\\\n",
    "$\\sqrt{n} = 10$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08bdc0cd-8af6-4cb6-a635-a1dbf3716a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence level: 0.0822\n"
     ]
    }
   ],
   "source": [
    "general_mean = 0.75\n",
    "n_stressed = 67\n",
    "sample_size = 100\n",
    "p = 0.67\n",
    "print(\n",
    "    \"Confidence level: %.4f\"\n",
    "    % np.round(\n",
    "        stats.binom_test(\n",
    "            n_stressed, sample_size, general_mean, alternative=\"two-sided\"\n",
    "        ),\n",
    "        4,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "47071042-e3aa-4329-9c9c-cd568d1e0f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence interval: [0.311622, 0.576940]\n"
     ]
    }
   ],
   "source": [
    "n_stress = 22\n",
    "n = 50\n",
    "alfa = 0.05\n",
    "print(\n",
    "    \"Confidence interval: [%f, %f]\"\n",
    "    % proportion_confint(n_stress, n, alpha=alfa, method=\"wilson\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "386f90a0-a37a-4c1a-a27f-727cd0de5a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.read_csv(\"~/MainDir/С4/pines.txt\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "778adbe1-e003-4c75-bffc-5abb874b1069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean expected square count: 23.36\n",
      "Power_divergenceResult(statistic=150.58904109589042, pvalue=2.574669774967279e-20)\n"
     ]
    }
   ],
   "source": [
    "area_size = 200.0\n",
    "square_count = 5\n",
    "x = frame['we'].to_numpy()\n",
    "y = frame['sn'].to_numpy()\n",
    "statistic = stats.binned_statistic_2d(x, y, None, statistic=\"count\", bins=5)\n",
    "expected_mean = float(len(x)) / (square_count ** 2)\n",
    "print(\"Mean expected square count: %.2f\" % expected_mean)\n",
    "\n",
    "# Чтобы сравнить распределение сосен с равномерным, посчитайте значение статистики хи-квадрат для полученных\n",
    "# 5х5 квадратов. Округлите ответ до двух знаков после десятичной точки.\n",
    "\n",
    "counts = statistic.statistic.reshape(-1)\n",
    "low = min(counts)\n",
    "high = max(counts)\n",
    "trees_count = sum(counts)\n",
    "expected_values = [expected_mean for x in range(0, square_count ** 2)]\n",
    "chi_square = stats.chisquare(\n",
    "    statistic.statistic.reshape(-1), expected_values, ddof=0, axis=0\n",
    ")\n",
    "print(chi_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa4734a-26a5-4ad2-a493-21ea58fccccc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
