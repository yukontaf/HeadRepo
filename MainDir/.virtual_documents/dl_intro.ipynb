import torch
import numpy
from tqdm.notebook import trange


device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))
print(f"Training on device {device}.")


A = numpy.random.randn(1000, 5000)
B = numpy.random.randn(5000, 2000)
get_ipython().run_line_magic("time", " C = numpy.matmul(A, B)")


A = torch.randn(1000, 5000)
B = torch.randn(5000, 2000)

get_ipython().run_line_magic("time", " C = torch.matmul(A, B)")


# если вы открыли тетрадку через Google Colab, то включите GPU
# (сверху слева Runtime -> Change runtime type... -> GPU)

A = torch.randn(1000, 5000).cuda()
B = torch.randn(5000, 2000).cuda()

get_ipython().run_line_magic("time", " C = torch.matmul(A, B)")


x = torch.tensor([1., 2., 3.])
y = torch.tensor([4., 5., 6.])
z = x + y

print(z)


# при создании переменных можно поставить флаг requires_grad
x = torch.tensor([1., 2., 3], requires_grad=True)

# с этим флагом мы можем делать те же операции, что и раньше
y = torch.tensor([4., 5., 6], requires_grad=True)
z = torch.dot(x, y)
print(z)


print(z.grad_fn)


z.backward()


print(x.grad)
print(y.grad)


import torch
import torch.nn as nn
# import torch.nn.functional as F
from torchvision import datasets, transforms

import matplotlib.pyplot as plt
get_ipython().run_line_magic("matplotlib", " inline")
from torch.optim.lr_scheduler import StepLR
import torchvision.transforms as transforms
import torch.onnx


def get_loader(train, batch_size):
    """Cкачает мнист и сохранит где-то рядом."""
    global dataset
    # Dataset в PyTorch -- это какой-то объект, который оборачивает сырые данные и делает с ними какой-нибудь препроцессинг
    dataset = datasets.MNIST('mnist', train=train, download=True,
        transform=transforms.ToTensor())
    
    # DataLoader делает из датасета генератор, который возвращает данные, сгруппированные по батчам
    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)
    
    return loader
    
train = get_loader(True, 64)
val = get_loader(False, 64)


model = nn.Sequential(
    #nn.Dropout(0.6),
    nn.Linear(784, 256),   nn.ReLU(), nn.Dropout(0.6),
    nn.Linear(256, 256),   nn.ReLU(), nn.Dropout(0.6),
    nn.Linear(256, 10),
    nn.LogSoftmax(dim=1)
)
model = model.to(device)


import numpy as np


def accuracy(model, val):
    model.eval()
    total = 0
    correct = 0
    for X, y in val:
      y = y.to(device)
      X = X.view(-1, 784).to(device)
      res = model(X)
      res = res.argmax(dim=1)
      total += res.shape[0]
      correct += (res == y).sum().item()
    return correct / total


optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
criterion = nn.NLLLoss()
# ^ попробуйте какой-нибудь другой и сравните, если ещё не уверовали в кроссэнтропию


# scheduler = StepLR(optimizer, gamma=0.9, step_size=2)


train_losses = []
for epoch in trange(10):
    model.train()
    for X, y in train:
        y = y.to(device)
        X = X.view(-1, 784).to(device)  # разгладим картинку в вектор
        optimizer.zero_grad()
        output = model(X)
        loss = criterion(output, y)
        loss.backward()

        train_losses.append(loss.item())
        # как думаете, зачем нужен .item()?
        # подсказка: лосс хранит информацию о своей истории
        # попробуйте убрать .item() и посмотреть на расход памяти
        optimizer.step()
    
    print(accuracy(model, train), accuracy(model, val))
        
plt.plot(train_losses)
plt.show()


for ds in train:
  dataset = ds
dummy_input = torch.randn(28, 28).view(-1, 784).to(device)
input_names = [ "actual_input_1" ] + [ "learned_%d" % i for i in range(16) ]
output_names = [ "output1" ]
torch.onnx.export(model,               # model being run
                   dummy_input,                         # model input (or a tuple for multiple inputs)
                  "intro.onnx",   # where to save the model (can be a file or file-like object)
                  export_params=True,        # store the trained parameter weights inside the model file
                  opset_version=10,          # the ONNX version to export the model to
                  do_constant_folding=True,  # whether to execute constant folding for optimization
                  input_names = ['input'],   # the model's input names
                  output_names = ['output'], # the model's output names
                  )



class Autoencoder(nn.Module):
    def __init__(self):
        super().__init__()
        
        self.encode = nn.Sequential(
            nn.Linear(784, 100),
            nn.ReLU(),
            nn.Linear(100, 20)
            
        )
        
        self.decode = nn.Sequential(
            nn.Linear(20, 100),
            nn.ReLU(),
            nn.Linear(100, 784),
            nn.Sigmoid()
            # картинки -- это тензоры со значениями от 0 до 1
            # нет особого смысла выводить что-то не из этого промежутка
        )
    
    def forward(self, x):
        return self.decode(self.encode(x))

model = Autoencoder()
criterion = torch.nn.MSELoss()
#                    ^ попробуйте также другие меры разности (например, абсолютную ошибку)
optimizer = torch.optim.Adam(model.parameters())


for epoch in trange(10):
    train_loss = 0
    for data, _ in train:
        #     ^ лэйблы нам не нужны
        data = data.view(-1, 784)
        
        optimizer.zero_grad()
        
        reconstructed = model(data)
        loss = criterion(data, reconstructed)
        
        loss.backward()

        train_loss += loss.item()
        optimizer.step()

    print('epoch %d, loss %.4f' % (epoch, train_loss / len(train)))


from matplotlib import animation
from matplotlib.animation import FuncAnimation
from IPython.display import HTML, display


def get(x):
    return train.dataset[x][0].view(1, 784)

def imshow(img):
    pic = img.numpy().astype('float')
    plt.axis('off')
    return plt.imshow(pic, cmap='Greys', animated=True)

def morph(inputs, steps, delay):
    # перегоняем в латентное пространство все картинки на входе
    latent = [model.encode(get(k)).data for k in inputs]
    fig = plt.figure()
    images = []
    for a, b in zip(latent, latent[1:] + [latent[0]]):
        for t in numpy.linspace(0, 1, steps):
            # получаем проинтерполированную точку
            c = a*(1-t)+b*t
            # ...и декодируем её в изображение
            morphed = model.decode(c).data
            morphed = morphed.view(28, 28)
            images.append([imshow(morphed)])
    
    ani = animation.ArtistAnimation(fig, images, interval=delay)

    display(HTML(ani.to_html5_video()))


morph(numpy.random.randint(0, len(train.dataset), 30), 20, 30)
